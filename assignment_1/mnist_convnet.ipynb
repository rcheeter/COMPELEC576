{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **mnist_convnet**\n",
    "- ELEC 576 HW 1\n",
    "- Robert Heeter\n",
    "- 4 October 2023\n",
    "\n",
    "## **Structure**:\n",
    "1) Set PyTorch metadata\n",
    "    - Seed\n",
    "    - TensorFlow output\n",
    "    - Whether to transfer to gpu (cuda)\n",
    "2) Import data\n",
    "    - Download data\n",
    "    - Create data loaders with batchsize, transforms, scaling\n",
    "3) Define model architecture, loss, and optimizer\n",
    "4) Define test and training loops\n",
    "    - Train:\n",
    "        - Get next batch\n",
    "        - Forward pass through model-\n",
    "        - Calculate loss\n",
    "        - Backward pass from loss (calculates the gradient for each parameter)\n",
    "        - Optimizer: performs weight updates\n",
    "5) Perform training over multiple epochs\n",
    "    - Each epoch:\n",
    "        - Call train loop\n",
    "        - Call test loop\n",
    "\n",
    "## **Acknowledgements**:\n",
    "- https://colab.research.google.com/drive/1i9KpbQyFU4zfq8zLLns8a2Kd8PRMGsaZ\n",
    "- https://github.com/motokimura/pytorch_tensorboard/blob/master/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set PyTorch metadata\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "try_cuda = True\n",
    "seed = 1000\n",
    "logging_interval = 10 # how many batches to wait before logging\n",
    "logging_dir = None\n",
    "\n",
    "# setting up the logging\n",
    "log_dir = os.path.join(os.getcwd(),'mnist_convnet_log', datetime.now().strftime('%b%d_%H-%M-%S'))\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# deciding whether to send to the cpu or not if available\n",
    "if torch.cuda.is_available() and try_cuda:\n",
    "    cuda = True\n",
    "    torch.cuda.mnaual_seed(seed)\n",
    "else:\n",
    "    cuda = False\n",
    "    torch.manual_seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import data\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.01307,), (0.3081,))])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('data', train=True, download=True, transform=transform),\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('data', train=False, download=True, transform=transform),\n",
    "                                          batch_size=test_batch_size,\n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Defining model architecture, loss, and optimizer\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        # x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # x = x.view(-1, 320) # (batch_size, units)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.fc2(x)\n",
    "        # x = F.softmax(x, dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define test and training loops\n",
    "\n",
    "eps=1e-13\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.NLLLoss(size_average=False)\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data) # forward pass\n",
    "        loss = criterion(torch.log(output+eps), target) # = sum_k(-t_k * log(y_k))\n",
    "        loss.backward() # backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % logging_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data)\n",
    "            )\n",
    "\n",
    "            # log train/loss to TensorBoard at every iteration\n",
    "            n_iter = (epoch - 1) * len(train_loader) + batch_idx + 1\n",
    "            writer.add_scalar('train/loss', loss.data, n_iter)\n",
    "\n",
    "#     log model parameters to TensorBoard at every epoch\n",
    "    for name, param in model.named_parameters():\n",
    "        layer, attr = os.path.splitext(name)\n",
    "        attr = attr[1:]\n",
    "        writer.add_histogram('{}/{}'.format(layer, attr), param.clone().cpu().data.numpy(), n_iter)\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.CrossEntropyLoss(size_average = False)\n",
    "    criterion = nn.NLLLoss(size_average = False)\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        test_loss += criterion(torch.log(output+eps), target,).item() # sum up batch loss (later, averaged over all test samples)\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), test_accuracy)\n",
    "    )\n",
    "\n",
    "    # log test/loss and test/accuracy to TensorBoard at every epoch\n",
    "    n_iter = epoch * len(train_loader)\n",
    "    writer.add_scalar('test/loss', test_loss, n_iter)\n",
    "    writer.add_scalar('test/accuracy', test_accuracy, n_iter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Perform training over multiple epochs\n",
    "\n",
    "# start training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir log_dir --port=8008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
